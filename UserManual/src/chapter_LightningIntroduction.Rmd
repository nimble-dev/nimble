<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->




```{r, chunk-LIinit, echo = FALSE}
# source the code
read_chunk(file.path('chunks', 'introExample_chunks.R'))  # one can put code chunks here if one wants
``` 


# Lightning introduction {#cha:lightning-intro}

## A brief example {#sec:brief-example}

Here we'll give a simple example of building a model and running some algorithms on the model, as well as creating our own user-specified algorithm. The goal is to give you a sense for what one can do in the system. Later sections will provide more detail.

We'll use the *pump* model example from BUGS^[The data set
  describes failure rates of some pumps.].  We could load the model
from the standard BUGS example file formats (Section \@ref(sec:readBUGSmodel)), but instead we'll show
how to enter it directly in R.

In this 'lightning introduction' we will:


  1. Create the model for the pump example.
  1. Compile the model.
  1. Create a basic MCMC configuration for the pump model.
  1. Compile and run the MCMC
  1. Customize the MCMC configuration and compile and run that.
  1. Create, compile and run a Monte Carlo Expectation Maximization (MCEM)
  algorithm, which illustrates some of the flexibility NIMBLE
  provides to combine R and NIMBLE.
  1. Write a short `nimbleFunction` to generate simulations from
  designated nodes of any  model.



## Creating a model {#sec:creating-model}
First we define the model code, its constants, data, and initial
values for MCMC.

```{r, inputPump}
``` 

Here `x[i]` is the number of failures recorded during a time
duration of length `t[i]` for the `i`$^{th}$ pump.
`theta[i]` is a failure rate, and the goal is estimate parameters
`alpha` and `beta`.  Now let's create the model and look at some of its nodes.

```{r, explorePump}
``` 


Notice that in the list of nodes, NIMBLE has introduced a new node,
`lifted_d1_over_beta`. We call this a 'lifted' node. Like R,
NIMBLE allows alternative parameterizations, such as the scale or rate
parameterization of the gamma distribution. Choice of parameterization
can generate a lifted node, as can using a link function or a
distribution argument that is an expression. It's helpful to know why
they exist, but you shouldn't need to worry about them.

Thanks to the plotting capabilities of the `igraph` package that
NIMBLE uses to represent the directed acyclic graph, we can plot the
model  (Figure 2.1).

```{r, plotPump, fig.cap="Directed Acyclic Graph plot of the pump model, thanks to the igraph package", fig.width=7.5, fig.height=7.5}
``` 

You are in control of the model.  By default, `nimbleModel` does
its best to initialize a model, but let's say you want to
re-initialize `theta`.  To simulate from the prior for `theta` (overwriting the
initial values previously in the model) we first need to be sure the
parent nodes of all `theta[i]` nodes are fully initialized, including any non-stochastic nodes such
as lifted nodes.  We then use the `simulate` function to simulate
from the distribution for `theta`.  Finally we use the
`calculate` function to 
calculate the dependencies of `theta`, namely `lambda` and the
log probabilities of `x` to ensure all parts of the
model are up to date.  First we show how
to use the model's `getDependencies` method to query information
about its graph.
<!---  TODO: the logic here is a bit weird - we say we want to know all parents of theta are initialized by our code actually finds dependencies of alpha+beta not parents of theta -->

```{r, manipPump}
"
``` 

Notice that the first `getDependencies` call returned dependencies
from `alpha` and `beta` down to the next stochastic nodes in the
model.  The second call requested only deterministic dependencies.
The call to `pump$simulate("theta")`
expands `"theta"` to include all nodes in `theta`.  After
simulating into `theta`, we can see that `lambda` and the log
probabilities of `x` still reflect the old values of `theta`, so
we `calculate` them and then see that they have been updated.

## Compiling the model {#sec:compiling-model}

Next we compile the model, which means generating C++ code, compiling
that code, and loading it back into R with an object that can be used just
like the uncompiled model. The values in the compiled model will be
initialized from those of the original model in R, but
the original and compiled models are distinct objects so any
subsequent changes in one will not be reflected in the other.

```{r, compilePump}
``` 

Note that the compiled model is used when running any NIMBLE algorithms via C++, so the model needs to be compiled before (or at the same time as) any compilation of algorithms, such as the compilation of the MCMC done in the next section.

## One-line invocation of MCMC {#sec:intro-runMCMC}

The most direct approach to invoking NIMBLE's MCMC engine is using the
`nimbleMCMC` function.  This function would generally take the code,
data, constants, and initial values as input, but it can also accept the (compiled or uncompiled)
model object as an argument. It provides a variety of options for executing and
controlling multiple chains of NIMBLE's default MCMC algorithm, and
returning posterior samples, posterior summary statistics,
and/or WAIC values.

For example, to execute two MCMC chains of 10,000 samples each, and
return samples, summary statistics, and WAIC values:

```{r, nimbleMCMCpump}
``` 

See Section \@ref(sec:nimbleMCMC) or `help(nimbleMCMC)` for more
details about using `nimbleMCMC`.

## Creating, compiling and running a basic MCMC configuration {#sec:creating-mcmc}
  
At this point we have initial values for all of the nodes in the model,
and we have both the original and compiled versions of the model. As a first algorithm
to try on our model, let's use NIMBLE's default MCMC. Note that conjugate relationships are detected for all nodes except for
`alpha`, on which the default sampler is a random walk Metropolis sampler.
<!--- ^[We haven't set up conjugate relationships for an 
%  exponential yet.] -->
<!---  footnote is true but not relevant as there is not a conj relationship for alpha in a gamma-distributed dependency -->

```{r, mcmcPump, fig.height=2.5}
``` 

Notice the posterior correlation between `alpha` and `beta`.
A measure of the mixing for each is the 
autocorrelation for each parameter, shown by the `acf` plots. 

## Customizing the MCMC {#sec:customizing-mcmc}

Let's add an adaptive
block sampler on `alpha` and `beta` jointly and see if that
improves the mixing. 

```{r, mcmcPump2, fig.height=2.5}
``` 

We can see that the block sampler has decreased the 
autocorrelation for both `alpha` and `beta`.  Of course these
are just short runs, and what we are really interested in is the
effective sample size of the MCMC per computation time, but that's not
the point of this example.

Once you learn the MCMC system, you can write your own samplers and
include them.  The entire system is written in nimbleFunctions.

## Running MCEM {#sec:running-mcem}

NIMBLE is a system for working with algorithms, not just an MCMC engine. So let's try maximizing the marginal likelihood for `alpha` and `beta` using Monte Carlo Expectation Maximization^[Note that for this model, one could analytically integrate over `theta` and then numerically maximize the resulting marginal likelihood.]. 

```{r, mcemPump, eval = runMCEMs, echo = runMCEMs}
``` 
```{r, dont-run-mcemPump, eval = !runMCEMs, echo = !runMCEMs}
``` 

Both estimates are within 0.01 of the values reported by
@George_Makov_Smith_1993^[Table 2 of the paper accidentally swapped the two estimates.]. 
<!---
[George, E.I., Makov, U.E. \& Smith,
A.F.M. 1993. Conjugate likelihood
 distributions. *Scand. J. Statist.* \textbf{20]:147-156.
-->
<!---  Their numbers were accidentally swapped in Table 2.}.   -->
Some discrepancy is to be expected since it is a Monte Carlo algorithm.

## Creating your own functions {#sec:creating-your-own}



Now let's see an example of writing our own algorithm and using it on
the model. We'll do something simple: simulating multiple values for a
designated set of nodes and calculating every part of the model that
depends on them. More details on programming in NIMBLE are in Part IV.

Here is our *nimbleFunction*:
```{r, nfPump}
``` 

Here are a few things to notice about the nimbleFunction.

  1. The `setup` function is written in R.  It creates relevant
  information specific to our model for use in the run-time code.  
  1. The `setup` code creates a *modelValues* object to hold multiple sets of
  values for variables  in the model provided.
  1. The `run` function is written in NIMBLE.  It carries out the
  calculations using the information determined once for each set of
  `model` and `nodes` arguments by the setup
  code. The run-time code is what will be compiled.
  1. The `run` code requires type information about the argument
  `n`.  In this case it is a scalar integer.  
  1. The for-loop looks just like R, but only sequential integer
  iteration is allowed.
  1. The functions `calculate` and `simulate`, which were
  introduced above in R, can be used in NIMBLE.
  1. The special function `copy` is used here to record values
  from the model into the modelValues object.  
  1. Multiple instances, or 'specializations', can be made by
  calling `simNodesMany` with different arguments.  Above, `simNodesTheta1to5` has
  been made by calling `simNodesMany` with the `pump` model and
  nodes `"theta[1:5]"` as inputs to
  the `setup` function, while `simNodesTheta6to10` differs by
  providing `"theta[6:10]"` as an argument.  The returned objects
  are objects of a uniquely
  generated R reference class with fields (member data) for the results of the
  `setup` code and a `run` method (member function). 
<!---  Arbitrary other methods can be provided with a `methods` argument, following the syntax of R's `setRefClass` function. -->
<!---  % NOTE: CJP removed previous sentence as I think it is too involved for the lightning intro - CJP -->


By the way, `simNodesMany` is very similar to a standard
`nimbleFunction` provided with NIMBLE, `simNodesMV`.

Now let's execute this nimbleFunction in R, before compiling it.

```{r, runPumpSimsR}
``` 

In this code we have initialized the values of `alpha` and `beta`
to their MLE and then recorded the `theta` values to use below.  Then we
have requested 10 simulations from
`simNodesTheta1to5`.  Shown are the first two simulation results
for `theta` and the log probabilities of `x`.  Notice that
`theta[6:10]` and the corresponding log probabilities for `x[6:10]` are unchanged because the nodes being simulated are only
`theta[1:5]`.  In R, this function runs slowly.

Finally, let's compile the function and run that version.

```{r, runPumpSimsC}
``` 

Given the same initial values and the same random number generator
seed, we got identical results for `theta[1:5]` and their dependencies, but it happened much faster.

