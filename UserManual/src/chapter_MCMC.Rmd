# (PART) Algorithms in NIMBLE {-}

```{r, echo=FALSE}
require(nimble)
``` 

# MCMC {#cha:mcmc}

```{r, MCMCchunk0, echo = FALSE}
# source the code
if(!require(nimble, warn.conflicts = FALSE, quietly = TRUE)) {
#source(file.path('..', '..', 'examples', 'demos', 'loadAllCode.R'))
}
require(methods, warn.conflicts = FALSE, quietly = TRUE)  # seems to be needed, but why?
require(igraph, warn.conflicts = FALSE, quietly = TRUE)  # same question
``` 

NIMBLE provides a variety of paths to creating and executing an MCMC algorithm, which differ greatly in their simplicity of use, and also in the options available and customizability.

The most direct approach to invoking the MCMC engine is using the `nimbleMCMC` function (Section \@ref(sec:nimbleMCMC)).  This one-line call creates and executes an MCMC, and provides a wide range of options for controlling the MCMC: specifying monitors, burn-in, and thinning, running multiple MCMC chains with different initial values, and returning posterior samples, summary statistics, and/or a WAIC value.  However, this approach is restricted to using NIMBLE's default MCMC algorithm; further customization of, for example, the specific samplers employed, is not possible.

The lengthier and more customizable approach to invoking the MCMC engine on a particular NIMBLE model object involves the following steps:


  1. (Optional) Create and customize an MCMC configuration for a particular model:
  
      a. Use `configureMCMC` to create an MCMC configuration (see Section \@ref(sec:mcmc-configuration)).  The configuration contains a list of samplers with the node(s) they will sample.
      a. (Optional) Customize the MCMC configuration: 
    
          i. Add, remove, or re-order the list of samplers (Section \@ref(sec:samplers-provided) and `help(samplers)` in R for details), including adding your own samplers (Section \@ref(sec:user-samplers));
          i. Change the tuning parameters or adaptive properties of individual samplers;
          i. Change the variables to monitor (record for output) and thinning intervals for MCMC samples.
  1. Use `buildMCMC` to build the MCMC object and its samplers either from the model (using default MCMC configuration) or from a customized MCMC configuration (Section \@ref(sec:build-compile-mcmc)).
  1. Compile the MCMC object (and the model), unless one is debugging and wishes to run the uncompiled MCMC.
  1. Run the MCMC and extract the samples (Sections \@ref(sec:runMCMC), \@ref(sec:executing-the-mcmc-algorithm) and \@ref(sec:extracting-samples)).
  1. Optionally, calculate the WAIC using the posterior samples (Section \@ref(sec:WAIC)).

Prior to version 0.8.0, NIMBLE provided two additional functions, `MCMCsuite` and `compareMCMCs`, to facilitate comparison of multiple MCMC algorithms, either internal or external to NIMBLE.  Those capabilities have been redesigned and moved into a separate package called `compareMCMCs`.

End-to-end examples of MCMC in NIMBLE can be found in Sections \@ref(sec:creating-mcmc)-\@ref(sec:customizing-mcmc) and Section \@ref(sec:mcmc-example-litters).
<!---  ### Creating an MCMC algorithm -->

<!---  A default MCMC algorithm can be created using `buildMCMC(model)`.  See Section \@ref(sec:build-compile-mcmc). -->

<!---  To customize properties of the MCMC algorithm -- including the sampling algorithms, joint (block) sampling of dimensions, tuning and adaptive properties of sampling algorithms, variables being monitored (posterior samples are collected), and the thinning interval for sample collection -- an MCMC configuration object (`conf`) must be created using `configureMCMC(model)`.  Properties of the MCMC algorithm can be modified using the `conf` object, after which an MCMC algorithm (`mcmc`) can be created using `buildMCMC(conf)`.  See Section \@ref(mcmc-configuration). -->

<!---  Both the `model` and `mcmc` should generally be compiled using `compileNimble`, for significantly faster execution (Section \@ref(sec:build-compile-mcmc)).  We'll refer to the compiled MCMC algorithm as `Cmcmc`. -->

<!---  ### Executing an MCMC algorithm and collecting samples -->

<!---  There are two methods available to execute an MCMC algorithm: -->

<!---   
%   1. `Cmcmc$run(...)`
%    1. `runMCMC(Cmcmc, ...)` -->
<!---  Using `Cmcmc$run(...)` provides lower-level options including extending an MCMC run (collecting additional samples from where it last stopped), and also collecting timing information for the internal sampling algorithms.  After executing an MCMC in this manner, posterior samples are extracted from within the `Cmcmc` object using `as.matrix(Cmcmc$mvSamples)`.  See Sections \@ref(sec:executing-the-mcmc-algorithm) and \@ref(sec:extracting-samples). -->

<!---  Using `runMCMC(Cmcmc, ...)` provides higher-level options such as running multiple chains, setting initial values, removing burn-in, and returning posterior samples in the form of a `coda` `mcmc` object.  Running an MCMC in this manner returns an array of samples, a list of sample arrays in the case of multiple chains, or optionally a `coda` object.  See Section \@ref(sec:runMCMC). -->

<!---  ### Other topics -->

<!---  In addition to details of the steps outlined above, this chapter also includes: -->

<!---   
% %%  1. NIMBLE's algorithm to search blocks of nodes for efficient joint (block) sampling (section \@ref(sec:default-mcmc-conf)) -->
<!---    1. Information about the sampling algorithms provided with NIMBLE (Section \@ref(sec:samplers-provided)) 
%   1. A detailed example of using the MCMC engine (section \@ref(sec:mcmc-example-litters)) --> 
<!---    1. Methods to automatically run WinBUGS, OpenBUGS, JAGS, Stan and/or multiple NIMBLE MCMCs on the same model (section \@ref(mcmc-suite-compare-mcmcs))  -->


## One-line invocation of MCMC: *nimbleMCMC* {#sec:nimbleMCMC}

The most direct approach to executing an MCMC algorithm in NIMBLE is using `nimbleMCMC`.  This single function can be used to create an underlying model and associated MCMC algorithm, compile both of these, execute the MCMC, and return samples, summary statistics, and a WAIC value.  This approach circumvents the longer (and more flexible) approach using `nimbleModel`, `configureMCMC`, `buildMCMC`, `compileNimble`, and `runMCMC`, which is described subsequently.

The `nimbleMCMC` function provides control over the:


  - number of MCMC iterations in each chain;
  - number of MCMC chains to execute;
  - number of burn-in samples to discard from each chain;
  - thinning interval on which samples should be recorded;
  - model variables to monitor and return posterior samples;
  - initial values, or a function for generating initial values for each chain;
  - setting the random number seed;
  - returning posterior samples as a matrix or a `coda` `mcmc` object;
  - returning posterior summary statistics; and
  - returning a WAIC value calculated using samples from all chains.


This entry point for using `nimbleMCMC` is the `code`, `constants`, `data`, and `inits` arguments that are used for building a NIMBLE model (see Chapters \@ref(cha:writing-models) and \@ref(cha:building-models)).  However, when using `nimbleMCMC`, the `inits` argument can also specify a list of lists of initial values that will be used for each MCMC chain, or a function that generates a list of initial values, which will be generated at the onset of each chain.  As an alternative entry point, a NIMBLE `model` object can also be supplied to `nimbleMCMC`, in which case this model will be used to build the MCMC algorithm.

Based on its arguments, `nimbleMCMC` optionally returns any combination of


  - Posterior samples,
  - Posterior summary statistics, and
  - WAIC value.


The above are calculated and returned for each MCMC chain.  Additionally, posterior summary statistics are calculated for all chains combined when multiple chains are run.

Several example usages of `nimbleMCMC` are shown below:

```{r, nimbleMCMC, eval=FALSE}
code <- nimbleCode({
    mu ~ dnorm(0, sd = 1000)
    sigma ~ dunif(0, 1000)
    for(i in 1:10)
        x[i] ~ dnorm(mu, sd = sigma)
})
data <- list(x = c(2, 5, 3, 4, 1, 0, 1, 3, 5, 3))
initsFunction <- function() list(mu = rnorm(1,0,1), sigma = runif(1,0,10))

# execute one MCMC chain, monitoring the "mu" and "sigma" variables,
# with thinning interval 10.  fix the random number seed for reproducible
# results.  by default, only returns posterior samples.
mcmc.out <- nimbleMCMC(code = code, data = data, inits = initsFunction,
                       monitors = c("mu", "sigma"), thin = 10,
                       niter = 20000, nchains = 1, setSeed = TRUE)

# note that the inits argument to nimbleModel must be a list of
# initial values, whereas nimbleMCMC can accept inits as a function
# for generating new initial values for each chain.
initsList <- initsFunction()
Rmodel <- nimbleModel(code, data = data, inits = initsList)

# using the existing Rmodel object, execute three MCMC chains with 
# specified burn-in.  return samples, summary statistics, and WAIC.
mcmc.out <- nimbleMCMC(model = Rmodel,
                       niter = 20000, nchains = 3, nburnin = 2000,
                       summary = TRUE, WAIC = TRUE)

# run ten chains, generating random initial values for each
# chain using the inits function specified above.
# only return summary statistics from each chain; not all the samples.
mcmc.out <- nimbleMCMC(model = Rmodel, nchains = 10, inits = initsFunction,
                       samples = FALSE, summary = TRUE)


```

See `help(nimbleMCMC)` for further details.





## The MCMC configuration {#sec:mcmc-configuration}

The MCMC configuration contains information needed for building an MCMC.  When no customization is needed, one can jump directly to the `buildMCMC` step below.  An MCMC configuration is an object of class `MCMCconf`, which includes:


  - The model on which the MCMC will operate
  - The model nodes which will be sampled (updated) by the MCMC
  - The samplers and their internal configurations, called control parameters
  - Two sets of variables that will be monitored (recorded) during execution of the MCMC and thinning intervals for how often each set will be recorded. Two sets are allowed because it can be useful to monitor different variables at different intervals


### Default MCMC configuration {#sec:default-mcmc-conf}

Assuming we have a model named `Rmodel`, the following will generate a default MCMC configuration:
```{r, mcmcConf, eval=FALSE}
mcmcConf <- configureMCMC(Rmodel)
```

The default configuration will contain a single sampler for each node in the model, and the default ordering follows the topological ordering of the model.

#### Default assignment of sampler algorithms

The default sampler assigned to a stochastic node is determined by the following, in order of precedence:


  1. If the node has no stochastic dependents, a `posterior_predictive` sampler is assigned.  This sampler sets the new value for the node simply by simulating from its distribution.
  1. If the node has a conjugate relationship between its prior distribution and the distributions of its stochastic dependents, a `conjugate` (`Gibbs') sampler is assigned.
  1. If the node follows a multinomial distribution, then a `RW_multinomial` sampler is assigned.  This is a discrete random-walk sampler in the space of multinomial outcomes.
  1. If a node follows a Dirichlet distribution, then a `RW_dirichlet` sampler is assigned.  This is a random walk sampler in the space of the simplex defined by the Dirichlet.
  1. If the node follows any other  multivariate distribution, then a `RW_block` sampler is assigned for all elements.  This is a Metropolis-Hastings adaptive random-walk sampler with a multivariate normal proposal [@Roberts_Sahu_1997].
  1. If the node is binary-valued (strictly taking values 0 or 1), then a `binary` sampler is assigned.  This sampler calculates the conditional probability for both possible node values and draws the new node value from the conditional distribution, in effect making a Gibbs sampler.
  1. If the node is otherwise discrete-valued, then a `slice` sampler is assigned [@Neal2003].
  1. If none of the above criteria are satisfied, then a `RW` sampler is assigned.  This is a Metropolis-Hastings adaptive random-walk sampler with a univariate normal proposal distribution.


These sampler assignment rules can be inspected, reordered, and easily modified using the system option `nimbleOptions("MCMCdefaultSamplerAssignmentRules")` and customized  `samplerAssignmentRules` objects.

Details of each sampler and its control parameters can be found by invoking `help(samplers)`.

#### Sampler assignment rules

The behavior of `configureMCMC` can be customized to control how samplers are assigned.  A new set of sampler assignment rules can be created using `samplerAssignmentRules`, which can be modified using the `addRule` and `reorder` methods, then passed as an argument to `configureMCMC`.  Alternatively, the default behavior of `configureMCMC` can be altered by setting the system option `MCMCdefaultSamplerAssignmentRules` to a custom `samplerAssignmentRules` object.  See `help(samplerAssignmentRules)` for details.

#### Options to control default sampler assignments

As a lightweight alternative to using `samplerAssignmentRules`, very basic control of default sampler assignments is provided via two arguments to `configureMCMC`.  The `useConjugacy` argument controls whether conjugate samplers are assigned when possible, and the  `multivariateNodesAsScalars` argument controls whether scalar elements of multivariate nodes are sampled individually. See `help(configureMCMC)` for usage details.
<!--- % The following optional control arguments to `configureMCMC()` may be used to override the default assignment of sampler algorithms: -->

<!--- 
%%   1.[useConjugacy (default `TRUE`)] If `TRUE`, conjugate samplers will be assigned to nodes determined to be in conjugate relationships.  If `FALSE`, no conjugate samplers will be assigned.
%   1.[multivariateNodesAsScalars (default `FALSE`)]  If `TRUE`, then independent scalar random walk Metropolis-Hastings samplers (`RW`) will be assigned to all scalar components comprising multivariate nodes.  This contrasts the default behavior of a single block sampler being assigned to multivariate nodes.  Regardless of the value of this argument, conjugate samplers will be assigned to conjugate (scalar and multivariate nodes), provided `useConjugacy = TRUE`. -->
 

#### Default monitors

The default MCMC configuration includes monitors on all top-level stochastic nodes of the model. Only variables that are monitored will have their samples saved for use outside of the MCMC. MCMC configurations include two sets of monitors, each with different thinning intervals.  By default, the second set of monitors (`monitors2`) is empty. 

#### Automated parameter blocking

The default configuration may be replaced by one generated from an automated parameter blocking algorithm.  This algorithm determines groupings of model nodes that, when jointly sampled with a `RW_block` sampler, increase overall MCMC efficiency.  Overall efficiency is defined as the effective sample size of the slowest-mixing node divided by computation time.  This is done by:

```{r, mcmcconf5, eval=FALSE}
autoBlockConf <- configureMCMC(Rmodel, autoBlock = TRUE)
```

Note that this using `autoBlock = TRUE` compiles and runs MCMCs, progressively exploring different sampler assignments, so it takes some time and generates some output.  It is most useful for determining effective blocking strategies that can be re-used for later runs.  The additional control argument `autoIt` may also be provided to indicate the number of MCMC samples to be used in each trial of the automated blocking procedure (default 20,000). 

### Customizing the MCMC configuration {#sec:customizing-mcmc-conf}

The MCMC configuration may be customized in a variety of ways, either through additional named arguments to `configureMCMC` or by calling methods of an existing `MCMCconf` object.

#### Controlling which nodes to sample

One can create an MCMC configuration with default samplers on just a particular set of nodes using the `nodes` argument to `configureMCMC`. The value for the `nodes` argument may be a character vector containing node and/or variable names.  In the case of a variable name, a default sampler will be added for all stochastic nodes in the variable.  The order of samplers will match the order of `nodes`.  Any deterministic nodes will be ignored.

If a data node is included in `nodes`, *it will be assigned a sampler*.  This is the only way in which a default sampler may be placed on a data node and will result in overwriting data values in the node.

#### Creating an empty configuration 
If you plan to customize the choice of all samplers, it can be useful to obtain a configuration with no sampler assignments at all.  This can be done by any of `nodes = NULL`, `nodes = character()`, or `nodes = list()`. 

#### Overriding the default sampler assignment rules
The default rules used for assigning samplers to model nodes can be overridden using the `rules` argument to `configureMCMC`.  This argument must be an object of class `samplerAssignmentRules`, which defines an ordered set of rules for assigning samplers.  Rules can be modified and reordered, to give different precedence to particular samplers, or to assign user-defined samplers (see section \@ref(sec:user-samplers)).  The following example creates a new set of rules (which initially contains the default assignment rules), reorders the rules, adds a new rule, then uses these rules to create an MCMC configuration object.

```{r, mcmcconfrules, eval=FALSE}
my_rules <- samplerAssignmentRules()
my_rules$reorder(c(8, 1:7))
my_rules$addRule(condition = quote(model$getDistribution(node) == "dmnorm"),
                 sampler = new_dmnorm_sampler)
mcmcConf <- configureMCMC(Rmodel, rules = my_rules)
```

In addition, the default behavior of `configureMCMC` can be altered by setting the system option `nimbleOptions(MCMCdefaultSamplerAssignmentRules = my_rules)`, or reset to the original default behavior using `nimbleOptions(MCMCdefaultSamplerAssignmentRules = samplerAssignmentRules())`.

#### Overriding the default sampler control list values
The default values of control list elements for all sampling algorithms may be overridden through use of the `control` argument to `configureMCMC`, which should be a named list. 
Named elements in the `control` argument will be used for all default samplers and any subsequent sampler added via `addSampler` (see below).  For example, the following will create the default MCMC configuration, except all `RW` samplers will have their initial `scale` set to 3, and none of the samplers (`RW`, or otherwise) will be adaptive.

```{r, mcmcconf6, eval=FALSE}
mcmcConf <- configureMCMC(Rmodel, control = list(scale = 3, adaptive = FALSE))
```

When adding samplers to a configuration using `addSampler`, the default control list can also be over-ridden.

#### Adding samplers to the configuration: *addSampler*

Samplers may be added to a configuration using the `addSampler` method of the `MCMCconf` object.  The first argument gives the node(s) to be sampled, called the `target`, as a character vector.   The second argument gives the type of sampler, which may be provided as a character string or a nimbleFunction object. Valid character strings are indicated in `help(samplers)` (do not include `"sampler_"`).  Added samplers can be labeled with a `name` argument, which is used in output of `printSamplers`.

Writing a new sampler as a nimbleFunction is covered in Section \@ref(sec:user-samplers).

The hierarchy of precedence for control list elements for samplers is:


  1. The `control` list argument to `addSampler`;
  1. The `control` list argument to `configureMCMC`;
  1. The default values, as defined in the sampling algorithm `setup` function.


Samplers added by `addSampler` will be appended to the end of current sampler list.  Adding a sampler for a node will *not* automatically remove any existing samplers on that node. 

#### Printing, re-ordering, modifying and removing samplers: *printSamplers*, *removeSamplers*, *setSamplers*, and *getSamplerDefinition*

The current, ordered, list of all samplers in the MCMC configuration may be printed by calling the `printSamplers` method. When you want to see only samplers acting on specific model nodes or variables, provide those names as an argument to `printSamplers`.  The `printSamplers` method accepts arguments controlling the level of detail displayed as discussed in its R help information.

```{r, printSamplers, eval=FALSE}
# Print all samplers
mcmcConf$printSamplers()

# Print all samplers operating on node "a[1]",
# or any of the "beta[]" variables
mcmcConf$printSamplers(c("a[1]", "beta"))

# Print all conjugate and slice samplers
mcmcConf$printSamplers(type = c("conjugate", "slice"))

# Print all RW samplers operating on "x"
mcmcConf$printSamplers("x", type = "RW")

# Print the first 100 samplers
mcmcConf$printSamplers(1:100)

# Print all samplers in their order of execution
mcmcConf$printSamplers(executionOrder = TRUE)
```

Samplers may be removed from the configuration object using `removeSamplers`, which accepts a character vector of node or variable names, or a numeric vector of indices.

```{r, removeSamplers, eval=FALSE}
# Remove all samplers acting on "x" or any component of it
mcmcConf$removeSamplers("x")

# Remove all samplers acting on "alpha[1]" and "beta[1]"
mcmcConf$removeSamplers(c("alpha[1]", "beta[1]"))

# Remove the first five samplers
mcmcConf$removeSamplers(1:5)

# Providing no argument removes all samplers
mcmcConf$removeSamplers()
```

Samplers to retain may be specified reordered using `setSamplers`, which also accepts a character vector of node or variable names, or a numeric vector of indices.

```{r, setSamplers2, eval=FALSE}
# Set the list of samplers to those acting on any components of the
# model variables "x", "y", or "z".
mcmcConf$setSamplers(c("x", "y", "z"))

# Set the list of samplers to only those acting on model nodes
# "alpha[1]", "alpha[2]", ..., "alpha[10]"
mcmcConf$setSamplers("alpha[1:10]")

# Truncate the current list of samplers to the first 10 and the 100th
mcmcConf$setSamplers(ind = c(1:10, 100))
```

The nimbleFunction definition underlying a particular sampler may be viewed using the `getSamplerDefinition` method, using the sampler index as an argument.  A node name argument may also be supplied, in which case the definition of the first sampler acting on that node is returned.  In all cases, `getSamplerDefinition` only returns the definition of the *first* sampler specified either by index or node name.

```{r, getSamplerDefinition, eval=FALSE}
# Return the definition of the third sampler in the mcmcConf object
mcmcConf$getSamplerDefinition(3)

# Return the definition of the first sampler acting on node "x",
# or the first of any indexed nodes comprising the variable "x"
mcmcConf$getSamplerDefinition("x")
```

#### Customizing individual sampler configurations: *getSamplers*, *setSamplers*, *setName*, *setSamplerFunction*, *setTarget*, and *setControl*

Each sampler in an `MCMCconf` object is represented by a sampler configuration as a `samplerConf` object.  Each `samplerConf` is a reference class object containing the following (required) fields: `name` (a character string), `samplerFunction` (a valid nimbleFunction sampler), `target` (the model node to be sampled), and `control` (list of control arguments).  The `MCMCconf` method `getSamplers` allows access to the `samplerConf` objects.  These can be modified and then passed as an argument to `setSamplers` to over-write the current list of samplers in the MCMC configuration object.  However, no checking of the validity of this modified list is performed; if the list of samplerConf objects is corrupted to be invalid, incorrect behavior will result at the time of calling `buildMCMC`.  The fields of a `samplerConf` object can be modified using the access functions `setName(name)`, `setSamplerFunction(fun)`, `setTarget(target, model)`, and `setControl(control)`.

Here are some examples:

```{r, getSetSamplers, eval=FALSE}
# retrieve samplerConf list
samplerConfList <- mcmcConf$getSamplers()

# change the name of the first sampler
samplerConfList[[1]]$setName("newNameForThisSampler")

# change the sampler function of the second sampler,
# assuming existance of a nimbleFunction 'anotherSamplerNF',
# which represents a valid nimbleFunction sampler.
samplerConfList[[2]]$setSamplerFunction(anotherSamplerNF)

# change the 'adaptive' element of the control list of the third sampler
control <- samplerConfList[[3]]$control
control$adaptive <- FALSE
samplerConfList[[3]]$setControl(control)

# change the target node of the fourth sampler
samplerConfList[[4]]$setTarget("y", model)   # model argument required

# use this modified list of samplerConf objects in the MCMC configuration
mcmcConf$setSamplers(samplerConfList)
```

#### Customizing the sampler execution order

The ordering of sampler execution can be controlled as well.  This allows for sampler functions to execute multiple times within a single MCMC iteration, or the execution of different sampler functions to be interleaved with one another.

The sampler execution order is set using the function `setSamplerExecutionOrder`, and the current ordering of execution is retrieved using `getSamplerExecutionOrder`.  For example, assuming the MCMC configuration object `mcmcConf` contains five samplers:

```{r, setSamplerExecutionOrder, eval=FALSE}
# first sampler to execute twice, in succession:
mcmcConf$setSamplerExecutionOrder(c(1, 1, 2, 3, 4, 5))

# first sampler to execute multiple times, interleaved:
mcmcConf$setSamplerExecutionOrder(c(1, 2, 1, 3, 1, 4, 1, 5))

# fourth sampler to execute 10 times, only
mcmcConf$setSamplerExecutionOrder(rep(4, 10))

# omitting the argument to setSamplerExecutionOrder()
# resets the ordering to each sampler executing once, sequentially
mcmcConf$setSamplerExecutionOrder()

# retrieve the current ordering of sampler execution
ordering <- mcmcConf$getSamplerExecutionOrder()

# print the sampler functions in the order of execution
mcmcConf$printSamplers(executionOrder = TRUE)
```

#### Monitors and thinning intervals: *printMonitors*, *getMonitors*, *addMonitors*, *setThin*, and *resetMonitors*

An MCMC configuration object contains two independent sets of variables to monitor, each with their own thinning interval: `thin` corresponding to `monitors`, and `thin2` corresponding to `monitors2`.  Monitors operate at the *variable* level.  Only entire model variables may be monitored.  Specifying a monitor on a *node*, e.g., `x[1]`, will result in the entire variable `x` being monitored.

The variables specified in `monitors`  and `monitors2` will be recorded (with thinning interval `thin`) into objects called `mvSamples` and `mvSamples2`, contained within the MCMC object. These are both *modelValues* objects; modelValues are NIMBLE data structures used to store multiple sets of values of model variables^[See Section \@ref(sec:modelValues-struct) for general information on modelValues.].  These can be accessed as the member data `mvSamples` and `mvSamples2` of the MCMC object, and they can be converted to matrices using `as.matrix` (see Section \@ref(sec:extracting-samples)).

Monitors may be added to the MCMC configuration either in the original call to `configureMCMC` or using the `addMonitors` method:
```{r, addMonitors, eval=FALSE}
# Using an argument to configureMCMC
mcmcConf <- configureMCMC(Rmodel, monitors = c("alpha", "beta"), 
                          monitors2 = "x")

# Calling a member method of the mcmcconf object
# This results in the same monitors as above
mcmcConf$addMonitors("alpha", "beta")
mcmcConf$addMonitors2("x")
```

Similarly, either thinning interval may be set at either step:
```{r, thinning, eval=FALSE}
# Using an argument to configureMCMC
mcmcConf <- configureMCMC(Rmodel, thin = 1, thin2 = 100)

# Calling a member method of the mcmcConf object
# This results in the same thinning intervals as above
mcmcConf$setThin(1)
mcmcConf$setThin2(100)
```

The current lists of monitors and thinning intervals may be displayed using the `printMonitors` method.  Both sets of monitors (`monitors` and `monitors2`) may be reset to empty character vectors by calling the `resetMonitors` method.  The methods `getMonitors`  and `getMonitors2` return the currently specified `monitors` and `monitors2` as character vectors.

#### Monitoring model log-probabilities

To record model log-probabilities from an MCMC, one can add monitors for *logProb* variables (which begin with the prefix `logProb_`) that correspond to variables with (any) stochastic nodes.   For example, to record and extract log-probabilities for the variables `alpha`, `sigma_mu`, and `Y`:
```{r, eval=FALSE}
mcmcConf <- configureMCMC(Rmodel)
mcmcConf$addMonitors("logProb_alpha", "logProb_sigma_mu", "logProb_Y")
Rmcmc <- buildMCMC(mcmcConf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
Cmcmc$run(10000)
samples <- as.matrix(Cmcmc$mvSamples)
``` 

The `samples` matrix will contain both MCMC samples and model log-probabilities.



## Building and compiling the MCMC {#sec:build-compile-mcmc}

Once the MCMC configuration object has been created, and customized to one's liking, it may be used to build an MCMC function:

```{r, buildMCMC, eval=FALSE}
Rmcmc <- buildMCMC(mcmcConf, enableWAIC = TRUE)
```

`buildMCMC` is a nimbleFunction.  The returned object `Rmcmc` is an instance  of the nimbleFunction specific to configuration `mcmcConf` (and of course its associated model).  

Note that if you would like to be able to calculate the WAIC of the model after the MCMC function has been run, you must set `enableWAIC = TRUE` as an argument to either `configureMCMC` or `buildMCMC`, or set `nimbleOptions(MCMCenableWAIC = TRUE)`, which will enable WAIC calculations for all subsequently built MCMC functions.  For more information on WAIC calculations, see Section \@ref(sec:WAIC) or `help(buildMCMC)` in R.

When no customization is needed, one can skip `configureMCMC` and simply provide a model object to `buildMCMC`. The following two MCMC functions will be identical:

```{r, overloadedBuildMCMC, eval=FALSE}
mcmcConf <- configureMCMC(Rmodel)   # default MCMC configuration
Rmcmc1 <- buildMCMC(mcmcConf)

Rmcmc2 <- buildMCMC(Rmodel)   # uses the default configuration for Rmodel
```

For speed of execution, we usually want to compile the MCMC function to C++ (as is the case for other NIMBLE functions).  To do so, we use `compileNimble`.  If the model has already been compiled, it should be provided as the `project` argument so the MCMC will be part of the same compiled project.  A typical compilation call looks like:

```{r, compileMCMC, eval=FALSE}
Cmcmc <- compileNimble(Rmcmc, project = Rmodel)
```

Alternatively, if the model has not already been compiled, they can be compiled together in one line:

```{r, compileMCMC2, eval=FALSE}
Cmcmc <- compileNimble(Rmodel, Rmcmc)
```

Note that if you compile the MCMC with another object (the model in this case), you'll need to explicitly refer to the MCMC component of the resulting object to be able to run the MCMC:

```{r, runMCMC2, eval=FALSE}
Cmcmc$Rmcmc$run(niter = 1000)
```



## User-friendly execution of MCMC algorithms: *runMCMC* {#sec:runMCMC}

Once an MCMC algorithm has been created using `buildMCMC`, the function `runMCMC` can be used to run multiple chains and extract posterior samples, summary statistics and/or a WAIC value.  This is a simpler approach to executing an MCMC algorithm, than the process of executing and extracting samples as described in Sections \@ref(sec:executing-the-mcmc-algorithm) and \@ref(sec:extracting-samples).

`runMCMC` also provides several user-friendly options such as burn-in, thinning, running multiple chains, and different initial values for each chain.  However, using `runMCMC` does not support several lower-level options, such as timing the individual samplers internal to the MCMC, continuing an existing MCMC run (picking up where it left off), or modifying the sampler execution ordering.

`runMCMC` takes arguments that will control the following aspects of the MCMC:
<!---  `runMCMC` has one mandatory argument: the (compiled or uncompiled) MCMC algorithm.  Other arguments to `runMCMC` are available to control: -->


  - Number of iterations in each chain;
  - Number of chains;
  - Number of burn-in samples to discard from each chain;
  - Thinning interval for recording samples;
  - Initial values, or a function for generating initial values for each chain;
  - Setting the random number seed;
  - Returning the posterior samples as a `coda` `mcmc` object;
  - Returning summary statistics calculated from each chains; and
  - Returning a WAIC value calculated using samples from all chains.

<!---  See `help(runMCMC)` for details of these arguments. -->

<!---  Other features of the MCMC can still be customized when using `runMCMC`, which is done using the MCMC configuration object.  This includes setting monitors, or customizing samplers (see Section \@ref(sec:customizing-mcmc-conf)).  The MCMC configuration object is then used to create an MCMC algorithm, which is compiled and passed as an argument to `runMCMC`. -->

<!---  When running a single chain, `runMCMC` returns a matrix of MCMC samples (as described in Section \@ref(sec:extracting-samples)).  When running multiple chains, a list of sample matrices is returned.  Using the argument `samplesAsCodaMCMC=TRUE`, a `coda` `mcmc` object, or in the case of multiple chains, a `coda` `mcmc.list` object is returned instead. -->

The following examples demonstrate some uses of `runMCMC`, and assume the existence of `Cmcmc`, a compiled MCMC algorithm.

```{r, runMCMC, eval=FALSE}
# run a single chain, and return a matrix of samples
mcmc.out <- runMCMC(Cmcmc)

# run three chains of 10000 samples, discard initial burnin of 1000,
# record samples thereafter using a thinning interval of 10,
# and return of list of sample matrices
mcmc.out <- runMCMC(Cmcmc, niter=10000, nburnin=1000, thin=10, nchains=3)

# run three chains, returning posterior samples, summary statistics,
# and the WAIC value for each chain
mcmc.out <- runMCMC(Cmcmc, nchains = 3, summary = TRUE, WAIC = TRUE)

# run two chains, and specify the initial values for each
initsList <- list(list(mu = 1, sigma = 1),
                  list(mu = 2, sigma = 10))
mcmc.out <- runMCMC(Cmcmc, nchains = 2, inits = initsList)

# run ten chains of 100,000 iterations each, using a function to 
# generate initial values and a fixed random number seed for each chain.
# only return summary statistics from each chain; not all the samples.
initsFunction <- function()
    list(mu = rnorm(1,0,1), sigma = runif(1,0,100))
mcmc.out <- runMCMC(Cmcmc, niter = 100000, nchains = 10,
                    inits = initsFunction, setSeed = TRUE,
                    samples = FALSE, summary = TRUE)
```


See `help(runMCMC)` for further details.


## Running the MCMC {#sec:executing-the-mcmc-algorithm}

The MCMC algorithm (either the compiled or uncompiled version) can be executed using the member method `mcmc$run` (see `help(buildMCMC)` in R).  The `run` method has one required argument, `niter`, the number of iterations to be run.

The `run` method has optional arguments `nburnin`, `thin` and `thin2`.  These can be used to specify the number of pre-thinning burnin samples to discard, and the post-burnin thinning intervals for recording samples (corresponding to `monitors` and `monitors2`).  If either `thin` and `thin2` are provided, they will override the thinning intervals that were specified in the original MCMC configuration object.

The `run` method has an optional `reset` argument.  When `reset = TRUE` (the default value), the following occurs prior to running the MCMC:

  1. All model nodes are checked and filled or updated as needed, in valid (topological) order.  If a stochastic node is missing a value, it is populated using a call to `simulate` and its log probability value is calculated.  The values of deterministic nodes are calculated from their parent nodes.  If any right-hand-side-only nodes (e.g., explanatory variables) are missing a value, an error results.
  1. All MCMC sampler functions are reset to their initial state: the initial values of any sampler control parameters (e.g., `scale`, `sliceWidth`, or `propCov`) are reset to their initial values, as were specified by the original MCMC configuration.
  1. The internal modelValues objects `mvSamples` and `mvSamples2` are each resized to the appropriate length for holding the requested number of samples (`niter/thin`, and `niter/thin2`, respectively).


When `mcmc$run(niter, reset = FALSE)` is called, the MCMC picks up from where it left off, continuing the previous chain and expanding the output as needed.  No values in the model are checked or altered, and sampler functions are not reset to their initial states.  

### Measuring sampler computation times: *getTimes* {#sec:sampler-time}

If you want to obtain the computation time spent in each sampler, you can set `time=TRUE` as a run-time argument and then use the method `getTimes()` obtain the times.  For example,

```{r, eval=FALSE}
Cmcmc$run(niter, time = TRUE)
Cmcmc$getTimes()
``` 
will return a vector of the total time spent in each sampler, measured in seconds. 
<!---  
%### Modifying the order of sampler execution: `samplerExecutionOrder` \label{sec:runtime-sampler-execution-order}
%The order in which the MCMC sampler functions execute can also be specified at MCMC runtime.  This is done using the argument `samplerExecutionOrder`.  Providing this runtime argument will override any modified execution ordering that was specified in the MCMC configuration.  For example,
% code chunk example (with eval=FALSE):
## interleave execution of the first sampler with other sampler functions 
% Cmcmc$run(niter, samplerExecutionOrder = c(1, 2, 1, 3, 1, 4, 1, 5))
-->

## Extracting MCMC samples {#sec:extracting-samples}

After executing the MCMC, the output samples can be extracted as follows:

```{r, samples, eval=FALSE}
mvSamples <- mcmc$mvSamples
mvSamples2 <- mcmc$mvSamples2
```

These *modelValues* objects can be converted into matrices using `as.matrix`:

```{r, as.matrix-samples, eval=FALSE}
samplesMatrix <- as.matrix(mvSamples)
samplesMatrix2 <- as.matrix(mvSamples2)
```

The column names of the matrices will be the node names of nodes in the monitored variables.  Then, for example, the mean of the samples for node `x[2]` could be calculated as:

```{r, access-samples, eval=FALSE}
mean(samplesMatrix[, "x[2]"])
```

Obtaining samples as matrices is most common, but see Section \@ref(sec:modelValues-struct) for more about programming with modelValues objects, especially if you want to write nimbleFunctions to use the samples.

## Calculating WAIC {#sec:WAIC}

Once an MCMC algorithm has been run, as described in Section \@ref(sec:executing-the-mcmc-algorithm), the WAIC [@Watanabe_2010] can be calculated from the posterior samples produced by the MCMC algorithm.  Note that in order to calculate the WAIC value after running an MCMC algorithm, the argument `enableWAIC = TRUE` must have been supplied to `configureMCMC` or to `buildMCMC`, or the `enableWAIC` NIMBLE option must have been set to `TRUE`.

The WAIC is calculated by calling the member method `mcmc$calculateWAIC` (see `help(buildMCMC)` in R for more details).  The `calculateWAIC` method has one required argument, `nburnin`, the number of initial samples to discard prior to WAIC calculation.  `nburnin` defaults to 0.

```{r, eval=FALSE}
Cmcmc$calculateWAIC(nburnin = 100)
```

Note that there is not a unique value of WAIC for a model. WAIC is calculated from
Equations 5, 12, and 13 in [@Gelman_etal_2014] (i.e. using \emph{p}WAIC2). In NIMBLE, the set
of all stochastic nodes monitored by the MCMC object will be treated as
$\theta$ for the purposes of Equation 5 from [@Gelman_etal_2014].

In many cases one would want $\theta$ to be the set of all stochastic nodes in the model, in which case the user *must* set the MCMC monitors to include all stochastic nodes; by default the MCMC monitors are only the top-level nodes of the model.

## k-fold cross-validation

The `runCrossValidate` function in NIMBLE performs k-fold cross-validation on a `nimbleModel` fit via MCMC.  More information can be found by calling `help(runCrossValidate)`. 

## Reversible Jump MCMC {#sec:rjmcmc}

Reversible Jump MCMC [@Green_1995] (RJMCMC) is a general framework for MCMC simulation in which the dimension of the parameter space can vary between iterates of the Markov chain. The reversible jump sampler can be viewed as an extension of the Metropolis-Hastings algorithm onto more general state spaces.

Given two models $M_1$ and $M_2$ of possibly different dimensions, the core idea of this technique is to remove the difference in the dimensions of models $M_1$ and $M_2$ by supplementing the corresponding parameters $\boldsymbol{\theta_1}$ and $\boldsymbol{\theta_2}$ with auxiliary variables $\boldsymbol{u}_{1 \rightarrow 2}$ and $\boldsymbol{u}_{2 \rightarrow 1}$ such that $(\boldsymbol{\theta_1}, \boldsymbol{u}_{1 \rightarrow 2})$ and $(\boldsymbol{\theta_2}, \boldsymbol{u}_{2 \rightarrow 1})$
are in bijection, $(\boldsymbol{\theta_2}, \boldsymbol{u}_{2 \rightarrow 1}) = \Psi(\boldsymbol{\theta_1}, \boldsymbol{u}_{1 \rightarrow 2})$. The corresponding Metropolis-Hastings acceptance probability is generalized accounting for the proposal density for the auxiliary variables.  

NIMBLE implements RJMCMC for variable selection using a univariate normal distribution as proposal density and supports two types of model specifications, depending on whether or not indicator variables are included. 
A reversible jump sampler can be added to a MCMC configuration object by calling the function `configureRJ`, which handles different model specification by assigning the corresponding specialized samplers, `RJ` and `RJ_indicator`. Information about the model specification is passed to `configureRJ` function by providing one of arguments `indicatorNodes` or `priorProb`. 
The `configureRJ` function modifies the MCMC configuration, and assigns a `RJ` sampler directly to the nodes specified in `targetNodes` when `priorProb` is provided. Otherwise a `RJ_indicator` sampler is assigned to nodes in `indicatorNodes`. In addition, the `configureRJ` removes the default NIMBLE sampler assigned to each node in `targetNodes`, and adds a toggled version of the default sampler that is run only when the node is the model.
 
<!--  See `help(configureRJ)` for details. -->

The `RJ` and `RJ_indicator` both use a univariate normal distribution as proposal density, whose mean and scale can be provided in the `control` list argument of `configureRJ` (by default `mean = 0` and `scale = 1`). An optional argument called `fixedValue` can be provided when the `priorProb` argument is present; this indicates the value taken by nodes in `targetNodes` when out of the model (by default 0). 
All arguments in `control` can accept one value that will be used for all samplers assigned to nodes `targetNodes`; alternatively each sampler can be customized by passing a vector of values whose length must equal the length of `targetNodes`.

In the following we provide an example for the two different model specifications. 

### Using indicator variables {#sec:rjmcmc-indicator}

Here we consider a normal linear regression in which two covariates `x1` and `x2` are given and only `x1` has to be included in the model.  

```{r indicators, results = "hide"}
## Linear regression with intercept and two covariates
code <- nimbleCode({
  beta0 ~ dnorm(0, sd = 100)
  beta1 ~ dnorm(0, sd = 100)
  beta2 ~ dnorm(0, sd = 100)
  sigma ~ dunif(0, 100) 
  
  z1 ~ dbern(psi)  ## indicator variable associated with beta1
  z2 ~ dbern(psi)  ## indicator variable associated with beta2
  psi ~ dbeta(1, 1) ## hyperprior on inclusion probability
  for(i in 1:N) {
    Ypred[i] <- beta0 + beta1 * z1 * x1[i] + beta2 * z2 * x2[i]
    Y[i] ~ dnorm(Ypred[i], sd = sigma)
  }
})

## simulate some data
set.seed(1)
N <- 100
x1 <- runif(N, -1, 1)
x2 <- runif(N, -1, 1) ## this covariate is not included
Y <- rnorm(N, 1.5 + 2 * x1, sd = 1)


## build the model and configure default MCMC

rIndicatorModel <- nimbleModel(code, constants = list(N = N),
                               data = list(Y = Y, x1 = x1, x2 = x2), 
                               inits=  list(beta0 = 0, beta1 = 0, beta2 = 0, sigma = sd(Y),
                               z2 = 1, z1 = 1, psi = 0.5))

indicatorModelConf <- configureMCMC(rIndicatorModel)
```

```{r print samplers}
## print NIMBLE default samplers
indicatorModelConf$printSamplers()
```

At this point we may want to modify the current configuration by adding a reversible jump sampler to allow for selection on `beta[1]` and `beta[2]` variables, which can be done by calling the `configureRJ` function.


```{r indicators: configureRJ, results = "hide"}
configureRJ(mcmcConf = indicatorModelConf,     
            targetNodes = c("beta1", "beta2"),
            indicatorNodes = c('z1', 'z2'),
            control = list(mean = c(1, 0), scale = 2))
```

The `targetNodes` argument should indicate the nodes for which we want to do variable selection. `targetNodes` will be expanded as described in Section \@ref(sec:arbitr-coll-nodes). I.e., either `targetNodes = "beta"` or `targetNodes = c("beta[1]", "beta[2]")` will assign a RJ sampler to each of `beta[1]` and `beta[2]` if `beta` is a vector of two values.
The same applies to `indicatorNodes`, which provides the indicator variables paired with nodes in `targetNodes`. Notice that `indicatorNodes` must be provided consistently with respect to `targetNodes`. E.g. if `targetNodes = "beta"` is a vector, then one should have `indicatorNodes = "z"` with `z` a vector as well; something like `indicatorNodes = c("z1", "z2")` will throw an error.


```{r indicators: print samplers after configureRJ}
indicatorModelConf$printSamplers()
```

An `RJ_indicator` sampler is assigned to `z[1]` and `z[2]` in place of the `binary` sampler, while the samplers for `beta[1]`and `beta[2]` have been changed to  `toggled` samplers, which still use the default `conjugate_dnorm_dnorm` sampler but only when the corresponding indicator variable is equal to $1$, thereby including the coefficient in the model. The two `RJ_indicator` samplers have different means for the proposal distribution but the same scale, as given in the `control` list of `configureRJ`.

Notice that the order of the sampler has changed, since `configureRJ` calls `removeSampler` for nodes in `targetNodes` and `indicatorNodes`, and subsequently `addSampler`, which appends the sampler to the end of current sampler list. Order can be modified by using `setSamplers`.

Also note that `configureRJ` modifies the existing sampler and returns `NULL`.

### Without indicator variables {#sec:rjmcmc-no-indicator}


We consider the same regression setting, but writing the model without the use of indicator variables. 

```{r no_indicators, results = "hide"}

## Linear regression with intercept and two covariates
code <- nimbleCode({
  beta0 ~ dnorm(0, sd = 100)
  beta1 ~ dnorm(0, sd = 100)
  beta2 ~ dnorm(0, sd = 100)
  sigma ~ dunif(0, 100)
  for(i in 1:N) {
    Ypred[i] <- beta0 + beta1 * x1[i] + beta2 * x2[i]
    Y[i] ~ dnorm(Ypred[i], sd = sigma)
  }
})

## build the model
rNoIndicatorModel <- nimbleModel(code, constants = list(N = N),
                               data = list(Y = Y, x1 = x1, x2 = x2), 
                               inits=  list(beta0 = 0, beta1 = 0, beta2 = 0, sigma = sd(Y)))

noIndicatorModelConf <- configureMCMC(rNoIndicatorModel)
```

```{r no indicators: print samplers}
## print NIMBLE default samplers
noIndicatorModelConf$printSamplers()
```

In this case, since there are no indicator variables, we need to pass to `configureRJ` the prior inclusion probabilities for each node in `targetNodes`, by specifying either one common value or a vector of values for the argument `priorProb`. Notice that this case does not allow for a stochastic prior. 


```{r no indicators: configureRJ, results = "hide"}
configureRJ(mcmcConf = noIndicatorModelConf,     
            targetNodes = c("beta1", "beta2"),
            priorProb = 0.5,
            control = list(mean = 0, scale = 2, fixedValue = c(1.5, 0)))
```

```{r no indicators: print samplers after configureRJ}
## print samplers after configureRJ
noIndicatorModelConf$printSamplers()
```

Since there are no indicator variables, the `RJ` sampler is assigned directly to `beta[1]` and `beta[2]` along with the `toggled` sampler. In addition in this case one can set the coefficient to a value different from $0$ via the `fixedValue` argument in the `control` list. 

If `fixedValue` is given when using `indicatorNodes` the values provided in `fixedValue` are ignored.  However the same behavior can be obtained in this situation, using a different model specification. For example, the model in \@ref(sec:rjmcmc-indicator) can be modified to have `beta1` equal to $1.5$ when in the model as follows:

```{r indicators v2, results = "hide", eval = FALSE}
  for(i in 1:N) {
    Ypred[i] <- beta0 + (1 - z1) * 1.5 * beta1 * x1[i] +
                z1 * beta1 * x1[i] + beta2 * z2 * x2[i]
    Y[i] ~ dnorm(Ypred[i], sd = sigma)
  }
```

## Samplers provided with NIMBLE {#sec:samplers-provided}

Most documentation of MCMC samplers provided with NIMBLE can be found by invoking `help(samplers)` in R.  Here we provide additional explanation of conjugate samplers and how complete customization can be achieved by making a sampler use an arbitrary log-likelihood function, such as to build a particle MCMC algorithm.



### Conjugate ('Gibbs') samplers

By default, `configureMCMC()` and `buildMCMC()` will assign conjugate samplers to all nodes satisfying a conjugate relationship, unless the option `useConjugacy = FALSE` is specified.  

The current release of NIMBLE supports conjugate sampling of the relationships listed in Table \@ref(tab:conjugacy)^[NIMBLE's internal definitions of these relationships can be viewed with `nimble:::conjugacyRelationshipsInputList`.].

```{r, child = 'tables/conjugacyTable.md'}
```

Conjugate sampler functions may (optionally) dynamically check that their own posterior likelihood calculations are correct.  If incorrect, a warning is issued.  However, this functionality will roughly double the run-time required for conjugate sampling.  By default, this option is disabled in NIMBLE.  This option may be enabled with
`nimbleOptions(verifyConjugatePosteriors = TRUE)`.

If one wants information about conjugate node relationships for other purposes, they can be obtained using the `checkConjugacy` method on a model.  This returns a named list describing all conjugate relationships.  The `checkConjugacy` method can also accept a character vector argument specifying a subset of node names to check for conjugacy. 
<!---  ### `binary (Gibbs) sampler` -->

<!---  The `binary` sampler performs Gibbs sampling for binary-valued nodes (strictly taking values 0 or 1).  This can only be used for nodes following either a `dbern(p)` or `dbinom(p, size=1)` distribution.  The `binary` sampler accepts no control list arguments. -->

<!---  ### `RW_multinomial sampler` -->

<!---  The `RW_multinomial` sampler operates exclusively on nodes following a multinomial distribution.  The sampler performs a series of Metropolis-Hastings steps between pairs of groups.  Proposals are generated via a draw from a binomial distribution, whereafter the proposed number density is moved from one group to another group.  The acceptance or rejection of these proposals follows a standard Metropolis-Hastings procedure.  Probabilities for the random binomial proposals are adapted to a target acceptance rate of 0.5. -->

<!---  The `RW_multinomial` sampler can be customized using `control` list arguments to set the adaptive properties of the sampler.  See `help(samplers)` for details.  -->
 
<!---  ### `RW_dirichlet sampler` -->

<!---  The `RW_dirichlet` sampler operates exclusively on nodes following a Dirichlet distribution, and is designed for the non-conjugate Dirichlet case.  The sampler performs independent adaptive Metropolis-Hastings updates on a reparameterization of the target distribution, expressed in terms of component univariate gamma distributions. -->

<!---  The `RW_dirichlet` sampler can be customized using `control` list arguments to set the adaptive properties of the sampler.  See `help(samplers)` for details. -->

<!---  ### Scalar Metropolis-Hastings random walk `RW sampler` -->

<!---  The `RW` sampler executes adaptive Metropolis-Hastings sampling with a normal proposal distribution, implementing the adaptation routine given in [@Shaby2011].  This sampler can be applied to any scalar continuous-valued stochastic node, and can optionally sample on a log scale. -->

<!---  The `RW` sampler can be customized using the `control` list argument to set the initial proposal distribution scale, the adaptive properties of the sampler, the reflective property of proposals, and whether to sample on a log scale.  See `help(samplers)` for details.  -->
 
<!---  Note that because we use a simple normal proposal distribution on all nodes, negative proposals may be simulated for non-negative random variables. These will be rejected, so the only downsides to this are some inefficiency and the presence of warnings during uncompiled (but not compiled) execution indicating `NA` or `NaN` values.  This can be avoided in some cases by using the option `reflective = TRUE`, which reflects proposal values to stay within the range of the target node distribution. -->

<!---  ### Multivariate Metropolis-Hastings `RW_block sampler` -->

<!---  The `RW_block` sampler performs a simultaneous update of one or more model nodes, using an adaptive Metropolis-Hastings algorithm with a multivariate normal proposal distribution [@Roberts_Sahu_1997], implementing the adaptation routine given in [@Shaby2011].  This sampler may be applied to any set of continuous-valued model nodes, to any single continuous-valued multivariate model node, or to any combination thereof.  -->

<!---  The `RW_block` sampler can be customized using the `control` list argument to set the initial proposal covariance, and the adaptive properties of the sampler.  See `help(samplers)` for details.  -->

<!---  ### `slice sampler` -->

<!---  The `slice` sampler performs slice sampling of the scalar node to which it is applied [@Neal2003].  This sampler can operate on either continuous-valued or discrete-valued scalar nodes.  The slice sampler performs a 'stepping out' procedure, in which the slice is iteratively expanded to the left or right by an amount `sliceWidth`.  This sampler is optionally adaptive, whereby the value of `sliceWidth` is adapted towards the observed absolute difference between successive samples. -->

<!---  The `slice` sampler can be customized using the `control` list argument to set the initial slice width, and the adaptive properties of the sampler.  See `help(samplers)` for details.  -->

<!---  ### Elliptical slice sampling: `ess sampler` -->

<!---  The `ess` sampler performs elliptical slice sampling of a single node, which must follow a multivariate normal distribution [@2010arXiv1001.0175M].  The algorithm is an extension of slice sampling [@Neal2003], generalized to the multivariate normal context.  An auxiliary variable is used to identify points on an ellipse (which passes through the current node value) as candidate samples, which are accepted contingent upon a likelihood evaluation at that point.  This algorithm requires no tuning parameters and therefore no period of adaptation, and may result in very efficient sampling from multivariate Gaussian distributions. -->

<!---  The `ess` sampler accepts no control list arguments.  See `help(samplers)` for details. -->

<!---  ### Hierarchical `crossLevel sampler` -->

<!---  This sampler is constructed to perform simultaneous updates across two levels of stochastic dependence in the model structure.  This is possible when all stochastic descendants of node(s) at one level have conjugate relationships with their own stochastic descendants.  In this situation, a Metropolis-Hastings algorithm may be used, in which a multivariate normal proposal distribution is used for the higher-level nodes, and the corresponding proposals for the lower-level nodes undergo Gibbs (conjugate) sampling.  The joint proposal is either accepted or rejected for all nodes involved based upon the Metropolis-Hastings ratio. -->

<!---  The `crossLevel` sampler can be customized using the `control` list argument to set the initial proposal covariance and the adaptive properties for the Metropolis-Hastings sampling of the higher-level nodes.  See `help(samplers)` for details.  -->

<!---  The requirement that all stochastic descendants of the `target` nodes must themselves have only conjugate descendants will be checked when the MCMC algorithm is built.  This sampler is useful when there is strong dependence across the levels of a model that causes problems with convergence or mixing. -->

### Customized log-likelihood evaluations: *RW_llFunction sampler*
 
Sometimes it is useful to control the log-likelihood calculations used for an MCMC updater instead of simply using the model.  For example, one could use a sampler with a log-likelihood that analytically (or numerically) integrates over latent model nodes.  Or one could use a sampler with a log-likelihood that comes from a stochastic approximation such as a particle filter (see below), allowing composition of a particle MCMC (PMCMC) algorithm [@Andrieu_Doucet_Holenstein_2010].  The `RW_llFunction` sampler handles this by using a Metropolis-Hastings algorithm with a normal proposal distribution and a user-provided log-likelihood function.  To allow compiled execution, the log-likelihood function must be provided as a specialized instance of a nimbleFunction.  The log-likelihood function may use the same model as the MCMC as a setup argument (as does the example below), but if so the state of the model should be unchanged during execution of the function (or you must understand the implications otherwise).

The `RW_llFunction` sampler can be customized using the `control` list argument to set the initial proposal distribution scale and the adaptive properties for the Metropolis-Hastings sampling.  In addition, the `control` list argument must contain a named `llFunction` element. This is the specialized nimbleFunction that calculates the log-likelihood; it must accept no arguments and return a scalar double number.  The return value must be the total log-likelihood of all stochastic dependents of the `target` nodes -- and, if `includesTarget = TRUE`, of the target node(s) themselves --  or whatever surrogate is being used for the total log-likelihood.  This is a required `control` list element with no default.  See `help(samplers)` for details. 

Here is a complete example:

```{r, RW_ll, eval=FALSE}
code <- nimbleCode({
    p ~ dunif(0, 1)
    y ~ dbin(p, n)
})

Rmodel <- nimbleModel(code, data = list(y=3), inits = list(p=0.5, n=10))

llFun <- nimbleFunction(
    setup = function(model) { },
    run = function() {
        y <- model$y
        p <- model$p
        n <- model$n
        ll <- lfactorial(n) - lfactorial(y) - lfactorial(n-y) +
              y * log(p) + (n-y) * log(1-p)
        returnType(double())
        return(ll)
    }
)

RllFun <- llFun(Rmodel)

mcmcConf <- configureMCMC(Rmodel, nodes = NULL)

mcmcConf$addSampler(target = "p", type = "RW_llFunction",
    control = list(llFunction = RllFun, includesTarget = FALSE))

Rmcmc <- buildMCMC(mcmcConf)
```
<!---  ### Terminal node `posterior_predictive sampler` 
% The `posterior_predictive` sampler is only appropriate for use on terminal stochastic nodes (that is, those having no stochastic dependencies).  Note that such nodes play no role in inference but have often been included in BUGS models to accomplish posterior predictive checks.  NIMBLE allows posterior predictive values to be simulated independently of running MCMC, for example by writing a nimbleFunction to do so.  This means that in many cases where terminal stochastic nodes have been included in BUGS models, they are not needed when using NIMBLE.
The `posterior_predictive` sampler functions by calling the `simulate` method of the relevant node, then updating model probabilities and deterministic dependent nodes.  The `posterior_predictive` sampler will automatically be assigned to all terminal, non-data stochastic nodes in a model by the default MCMC configuration, so it is uncommon to manually assign this sampler.  The `posterior_predictive` sampler accepts no control list arguments. -->


### Particle MCMC sampler
For state space models, a particle MCMC (PMCMC) sampler can be specified for top-level parameters.  This sampler is described in Section \@ref(sec:particle-mcmc).

## Detailed MCMC example: *litters* {#sec:mcmc-example-litters}

Here is a detailed example of specifying, building, compiling, and running two MCMC algorithms.  We use the `litters` example from the BUGS examples.

```{r, MCMC-litters, eval=FALSE}

###############################
##### model configuration #####
###############################

# define our model using BUGS syntax
litters_code <- nimbleCode({
    for (i in 1:G) {
        a[i] ~ dgamma(1, .001)
        b[i] ~ dgamma(1, .001)
        for (j in 1:N) {
            r[i,j] ~ dbin(p[i,j], n[i,j])
            p[i,j] ~ dbeta(a[i], b[i]) 
        }
        mu[i] <- a[i] / (a[i] + b[i])
        theta[i] <- 1 / (a[i] + b[i])
    }
})

# list of fixed constants
constants <- list(G = 2,
                  N = 16,
                  n = matrix(c(13, 12, 12, 11, 9, 10, 9,  9, 8, 11, 8, 10, 13,
                      10, 12, 9, 10,  9, 10, 5,  9,  9, 13, 7, 5, 10, 7,  6, 
                      10, 10, 10, 7), nrow = 2))

# list specifying model data
data <- list(r = matrix(c(13, 12, 12, 11, 9, 10,  9, 9, 8, 10, 8, 9, 12, 9,
                 11, 8, 9,  8,  9,  4, 8,  7, 11, 4, 4, 5 , 5, 3,  7, 3, 
                 7, 0), nrow = 2))

# list specifying initial values
inits <- list(a = c(1, 1),
              b = c(1, 1),
              p = matrix(0.5, nrow = 2, ncol = 16),
              mu    = c(.5, .5),
              theta = c(.5, .5))

# build the R model object
Rmodel <- nimbleModel(litters_code,
                      constants = constants,
                      data      = data,
                      inits     = inits)


###########################################
##### MCMC configuration and building #####
###########################################

# generate the default MCMC configuration;
# only wish to monitor the derived quantity "mu"
mcmcConf <- configureMCMC(Rmodel, monitors = "mu")

# check the samplers assigned by default MCMC configuration
mcmcConf$printSamplers()

# double-check our monitors, and thinning interval
mcmcConf$printMonitors()

# build the executable R MCMC function
mcmc <- buildMCMC(mcmcConf)

# let's try another MCMC, as well,
# this time using the crossLevel sampler for top-level nodes

# generate an empty MCMC configuration
# we need a new copy of the model to avoid compilation errors
Rmodel2 <- Rmodel$newModel()
mcmcConf_CL <- configureMCMC(Rmodel2, nodes = NULL, monitors = "mu")

# add two crossLevel samplers
mcmcConf_CL$addSampler(target = c("a[1]", "b[1]"), type = "crossLevel")
mcmcConf_CL$addSampler(target = c("a[2]", "b[2]"), type = "crossLevel")

# let's check the samplers
mcmcConf_CL$printSamplers()

# build this second executable R MCMC function
mcmc_CL <- buildMCMC(mcmcConf_CL)


###################################
##### compile to C++, and run #####
###################################

# compile the two copies of the model
Cmodel <- compileNimble(Rmodel)
Cmodel2 <- compileNimble(Rmodel2)

# compile both MCMC algorithms, in the same
# project as the R model object
# NOTE: at this time, we recommend compiling ALL
# executable MCMC functions together
Cmcmc <- compileNimble(mcmc, project = Rmodel)
Cmcmc_CL <- compileNimble(mcmc_CL, project = Rmodel2)

# run the default MCMC function,
# and example the mean of mu[1]
Cmcmc$run(1000)
cSamplesMatrix <- as.matrix(Cmcmc$mvSamples)
mean(cSamplesMatrix[, "mu[1]"])

# run the crossLevel MCMC function,
# and examine the mean of mu[1]
Cmcmc_CL$run(1000)
cSamplesMatrix_CL <- as.matrix(Cmcmc_CL$mvSamples)
mean(cSamplesMatrix_CL[, "mu[1]"])


###################################
#### run multiple MCMC chains #####
###################################

# run 3 chains of the crossLevel MCMC
samplesList <- runMCMC(Cmcmc_CL, niter=1000, nchains=3)

lapply(samplesList, dim)
```

## Comparing different MCMCs with *MCMCsuite* and *compareMCMCs* {#mcmc-suite-compare-mcmcs}

Please see the `compareMCMCs` package for the features previously provided by `MCMCsuite` and `compareMCMCs` in NIMBLE (until version 0.8.0).  The `compareMCMCs` package provides tools to automatically run MCMC in nimble (including multiple sampler configurations), WinBUGS, OpenBUGS, JAGS, Stan, or any other engine for which you provide a simple common interface.  The package makes it easy to manage comparison metrics and generate html pages with comparison figures.
